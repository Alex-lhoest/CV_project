{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEN0016 - Computer Vision \n",
    "## Project Part. 2 - Ellipse matching and performance assessment \n",
    "Antoine Rousseau, Fran√ßois Blistein, Renaud Vandeghen, Alexandre Lhoest (group 7)\n",
    "\n",
    "## 1. Description of the work\n",
    "\n",
    "The aim of the project is to develop modules to detect/match ellipses in images and to assess the performances of this modules. The image database is composed of two different types of images : \n",
    "\n",
    "  -  Annotated line images (sudoku, soccer and road)\n",
    "  -  Annotated ellipse images :  soccer field images where one will have to extract the white circles of the field marking (one central and two side half-circles) and eye infra-red images where one will have to find the pupil. \n",
    "\n",
    "The global work is subdivided into four tasks : \n",
    "\n",
    "  -  Task 2.1 : performance assessment of line segment detection. The task is to assess the performances of the line detection modules developed during the first part of the project. To do so, one will describe the metrics used and present the obtained results on these annotated images.\n",
    "  -  Task 2.2 : ellipse matching. The main objective is to detect and local elliptical structures in images using Machine Learning. Practically, two programs have to be developed : \n",
    "     - For the pupil of the eyes images, the output must be the regression parameters of the detected ellipse ;\n",
    "     - For the soccer images, the output must be the bounding box of the (1,2 or 3) detected ellipses. \n",
    "  -  Task 2.4 : performance assessment of the ellipse matching module. The goal is to assess the performances of the ellipse detection and matching module. To do so, one will describe the metrics used and present the obtained results on these annotated images. Practically, there are three quantitative assessments to measure quality of : \n",
    "     - [Classification Task] The detection of ellipses in input images ;\n",
    "     - [Regression task on bounding boxes] The obtained position of the bounding boxes of the circles of the field marking in soccer images ;\n",
    "     - [Regression task on ellipse parameters] The obtained parameters of the ellipes for the pupils in eye images. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1 : performance assessment of line segment detection\n",
    "\n",
    "During the first part of the project, the goal was to find efficient ways to extract and detect lines in five types of images : Building, PCB, Soccer, Road and Sudoku. For this purpose, some preprocessing methods were applied to the images (GaussianBlur...), then one applied edges detection method such as Canny or AdaptiveThreshold and, finally, one could increase the quality of the detections using postprocessing methods as dilation. By the end of this first part of the projet, one was able to classify edge pixels as being part of a line or not. This will be the basis of the performance assessment. \n",
    "\n",
    "Indeed, one wants to assess the performance of line segment detection developed before. To do so, a database of annotated lines images (sudoku, soccer and road) are provided. One will evaluate the performance as follows : \n",
    "  -  Based on confusion matrix definition, one will compare the line segment detection module with the annotations. For the edge pixels assumed to be part of a line segment, one will check if they belong actually to an annotated lines. If so, it will count for a true positive pixel. If not, it will count for a false positive pixels. In the same idea, a true negative pixel is a non-edge pixel that is actually annotated as being a non-edge pixel. Conversly, a false negative pixel is a non-edge pixel that is annotated to belong to a line. In order to have relative results, those number of true/false positive/negative pixels will be divided by the total number of edge pixels computed during the first part of the project. \n",
    "  -  Another qualitative way to assess the performance of line segment detection is to compare the detected lines at the Hough Line Transform output and the annotated lines. The goal will be to count the number of Hough lines that correspond to true lines. In order to do so, one will compare the number of pixels that belong to both a Hough Line and annotated lines. Thanks to this, it will be chosen if it actually represents the same line (with a tolerance parameter called alpha, tuned by hand for each different image types). This assessment method is less precised than the first one, but it gives a complementary evaluation. \n",
    "\n",
    "In order to get consistent results, the two methods are applied to the full image datasets for the three types of images. The edge detection methods developped during the first part of the project are assumed to be good if they give high percentage of true positive pixels and true negative pixels. The results are given below. It is not surprising to see that the sudoku images have the best results. It was actually the easiest type of images to process. For soccer and road images, the percentage of true positive pixels is lower. This is not so surprising. Indeed, during the first part of the project, one decided mainly to reject all the false lines that were detected by the method. This makes that lots of the true lines were also rejected. Therefore, if one looks at the percentage of true negative pixels, the percentages are way better in the case of soccer and road images. \n",
    "\n",
    "Finally, it will appear interesting to look at the impact of the dilation postprocessing on the performance assessment. This means, what happens if one dilates the detected edges by a factor 2, 3, 4,... In order to visualize it, one will generate the ROC curve associated to this. In a sense, it the dilation is performed with a factor 0, this means that the program will detect no true positive pixels and no false positive (0,0). If the dilation is performed with a factor really huge, the dilation will make the program will never detect any true negative or false negative pixels (1,1). The resulting plots are given below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sudoku images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                     # Numerical algorithms on arrays\n",
    "import cv2                             # OpenCV\n",
    "from matplotlib import pyplot as plt   # Plot library\n",
    "import matplotlib.cm as cm             # Image color map \n",
    "import Codes.tools                     # A few helpers to plot multiple images\n",
    "import pandas as pd\n",
    "from Codes.Part1.sudoku_lines import sudoku_lines_eval, roc_curve_sudoku\n",
    "from Codes.Part1.road_lines import road_lines_eval, roc_curve_road\n",
    "from Codes.Part1.soccer_lines import soccer_lines_eval, roc_curve_soccer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation_parameter = 1\n",
    "\n",
    "true_pos, false_pos, true_neg, false_neg, lines_detected = sudoku_lines_eval(dilation_parameter)\n",
    "print(\"Pourcent of true positive pixels = \", true_pos, \"%\")\n",
    "print(\"Pourcent of false negative pixels = \", false_neg, \"%\")\n",
    "\n",
    "print(\"Pourcent of true negative pixels = \", true_neg, \"%\")\n",
    "print(\"Pourcent of false positive pixels = \", false_pos, \"%\")\n",
    "\n",
    "print(lines_detected,\"% of the Hough lines are real lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soccer images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation_parameter = 1\n",
    "\n",
    "true_pos, false_pos, true_neg, false_neg, lines_detected = soccer_lines_eval(dilation_parameter)\n",
    "print(\"Pourcent of true positive pixels = \", true_pos, \"%\")\n",
    "print(\"Pourcent of false negative pixels = \", false_neg, \"%\")\n",
    "\n",
    "print(\"Pourcent of true negative pixels = \", true_neg, \"%\")\n",
    "print(\"Pourcent of false positive pixels = \", false_pos, \"%\")\n",
    "\n",
    "print(lines_detected,\"% of the Hough lines are real lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Road images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation_parameter = 1\n",
    "\n",
    "true_pos, false_pos, true_neg, false_neg, lines_detected = road_lines_eval(dilation_parameter)\n",
    "print(\"Pourcent of true positive pixels = \", true_pos, \"%\")\n",
    "print(\"Pourcent of false negative pixels = \", false_neg, \"%\")\n",
    "\n",
    "print(\"Pourcent of true negative pixels = \", true_neg, \"%\")\n",
    "print(\"Pourcent of false positive pixels = \", false_pos, \"%\")\n",
    "\n",
    "print(lines_detected,\"% of the Hough lines are real lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The ROC curve in the case of the Sudoku and Soccer images show that a dilation does increase the true and false positive rates (dilation parameter going from 1 to 5). The first peak of the curve corresponds to a dilation of 1, then the two rates tend to increase. However, the false positive rate increases much faster than the true postive rate, which makes that it is better, in this case, to keep the dilation parameter equal to 1. This is sensible. In fact, increasing the width of the lines increase both the rate of the true positive pixels and the rate of the false negative pixels. \n",
    "\n",
    "However, in the case of the Road images, it appears that a dilation is really good to increase the true positive rate, as the false positive rate remains really low. So, the range of dilation_parameters is larger than for the previous cases (dilation parameter in [1,5,10,15,20]). From the curve, one can observe that a dilation parameter equal to 15 could be great to increase the performance of the line segment detection of this type of images. Beyong this value, the rate of false positive becomes too important.\n",
    "\n",
    "#### Sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_vector,false_pos_vector = roc_curve_sudoku()\n",
    "\n",
    "print(true_pos_vector)\n",
    "print(false_pos_vector)\n",
    "\n",
    "plt.title(\"Sudoku ROC curve\")\n",
    "plt.plot(false_pos_vector, true_pos_vector)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soccer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_vector,false_pos_vector = roc_curve_soccer()\n",
    "\n",
    "print(true_pos_vector)\n",
    "print(false_pos_vector)\n",
    "\n",
    "plt.title(\"Soccer ROC curve\")\n",
    "plt.plot(false_pos_vector, true_pos_vector)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_vector,false_pos_vector = roc_curve_road()\n",
    "\n",
    "print(true_pos_vector)\n",
    "print(false_pos_vector)\n",
    "\n",
    "plt.title(\"Road ROC curve\")\n",
    "plt.plot(false_pos_vector, true_pos_vector)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2 : ellipse matching\n",
    "\n",
    "In this task, the main objectives are the detection of the number of ellipses on the eyes and soccer images but also provide accurate values for their parameters, such as their location, orientation and size. \n",
    "\n",
    "### Soccer images\n",
    "\n",
    "For the soccer images, we decide to use the network Yolo to classify the ellipses on the soccer images. You Only Look Once (YOLO) is a pretrained classifier for object detection using a bounding box. We have used the configuration YOLOv3 with some modifications so that YOLO only detects the ellipses of the soccer field in a reasonable time according to the capacity of our GPU.\n",
    "\n",
    "Our dataset have been randomly split into the training set, the validation set and the test set that contains 70%, 20% and 10% of the soccer images, respectively."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4 :  performance assessment of the ellipse matching module\n",
    "\n",
    "### Soccer images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_real_ellipses: 101\n",
      "nb_found_ellipses: 99\n",
      "mean IOU: 0.8798217002636028\n"
     ]
    }
   ],
   "source": [
    "from Codes.IOU_soccer import IOU_soccer\n",
    "\n",
    "nb_real_ellipses, nb_found_ellipses, files_bad_ellipses, mean_IOUs, list_IOU = IOU_soccer()\n",
    "\n",
    "print(\"nb_real_ellipses: {}\".format(nb_real_ellipses))\n",
    "print(\"nb_found_ellipses: {}\".format(nb_found_ellipses))\n",
    "print(\"mean IOU: {}\".format(mean_IOUs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
