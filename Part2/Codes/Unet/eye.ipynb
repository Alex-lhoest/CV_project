{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction import make_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eye images\n",
    "\n",
    "For the eye images, we decided to use semantic segmentation to detect the ellipse of the pupil. The architecture used is the Unet neural network. This network has first an encoding part, which captures the features of the input image by using convolutional layer and max pooling layer, followed by a decoder part, which localizes them, by using convolutional layer and upsampling.  \n",
    "The training has been performed with a GPU to lower the computational time.\n",
    "\n",
    "Our dataset have been randomly split into the training set (1838 images), the validation set (525 images) and the test set (262 images) which represents 70%, 20% and 10% of the eye dataset, respectively.  \n",
    "We decided to not use data augmentation such as random horizontal flipping in the training dataset even though we are aware that this could lead to better results.  \n",
    "\n",
    "For semantic segmentation, each training and evaluation images must have its mask ground truth.  \n",
    "We used the fitEllipse function of opencv to obtain the $a, b, x_c, y_c, \\theta$ to then draw the corresponding ellipse which will be used as mask.  \n",
    "\n",
    "The loss used during the training is the binary cross entropy $ = -\\sum (y \\log(p) + (1-y) \\log(1-p))$, where $y$ is the ground truth label and $p$ is the predicted label.  \n",
    "All the hyperparameters have been set to their default value.\n",
    "\n",
    "In order to prevent overfitting, we save the weights after an epoch if the validation loss is improved. Thus for inference, we will use the weights which gave us the best evaluation loss.  \n",
    "\n",
    "We decided to train the eye images with and without preprocessing.  \n",
    "The validation loss can be seen on the following graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "During inference, the network predicts for each pixel the confidence it has to be true.  \n",
    "A threshold analyzis will be carried out in section 2.4 to determine what value(s) use.  \n",
    "\n",
    "Semantic segmentation gives nice and clear results for pupil detection.  \n",
    "The green pixels are the True Positive ones.  \n",
    "The red pixels are the False Positive ones.  \n",
    "The blue pixels are the False Negative ones.  \n",
    "The pixels which are not colored are the True Negative ones.  \n",
    "Thus the green and red pixels give the ground truth mask whereas the green and blue give the predicted mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0, Recall : 0.0, Miss Rate : 1.0, Accuracy : 0.9848567708333333\n",
      "a : 0, b : 0, x : 0, y : 0, theta : 0\n"
     ]
    }
   ],
   "source": [
    "make_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|threshold|precision|recall|miss rate|accuracy|IoU|\n",
    "|---|---|---|---|---|---|\n",
    "|0.6|0.905648|**0.9247416**|**0.07525836**|0.99622035|0.8420224|\n",
    "|0.7|0.92063624|0.9111186|0.08888141|**0.9962832**|**0.8434102**|\n",
    "|0.8|0.9334427|0.8914266|0.10857338|0.9962517|0.84036845|\n",
    "|0.9|**0.954061**|0.85160315|0.14839688|0.99594104|0.8218886| \n",
    "\n",
    "<center> Mean value over the test set </center>\n",
    "\n",
    "\n",
    "|threshold|precision|recall|miss rate|accuracy|IoU|\n",
    "|---|---|---|---|---|---|\n",
    "|0.6|0.9342046|**0.973418**|**0.02658202**|0.9976758|0.8867159|\n",
    "|0.7|0.95079553|0.9596702|0.04032983|0.9977018|0.8881278|\n",
    "|0.8|0.964836|0.93920517|0.06079482|**0.9977213**|**0.88967115**|\n",
    "|0.9|**0.98560476**|0.8975742|0.10242577|0.99747396|0.87355137|  \n",
    "\n",
    "<center> Median value of the test set </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
